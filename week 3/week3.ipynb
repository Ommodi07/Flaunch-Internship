{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224d4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the YouTube video link: https://www.youtube.com/watch?v=CO4E_9V6li0&t=756s&pp=ygULbGxtIHByb2plY3Q%3D\n",
      "Enter the number of quiz questions: 5\n",
      "Generated Output:\n",
      " {\n",
      "  \"summary\": \"This transcript is a tutorial on building a cold email generator for software service companies using the Llama 3.1 language model. The tool automates the process of identifying potential clients through job postings, extracting relevant skills, and generating personalized cold emails with links to the company's portfolio. \\n\\nThe tutorial covers using various tools and technologies, including:\\n\\n* **Llama 3.1:** An open-source LLM used for text generation and information extraction.\\n* **Langchain:** A framework for building applications with LLMs.\\n* **Chroma DB:** A vector database for storing and querying information based on semantic meaning.\\n* **Streamlit:** A framework for building interactive user interfaces.\\n\\nThe tutorial demonstrates how to scrape job postings from websites, extract relevant information using Llama 3.1, store and query relevant portfolio links in Chroma DB, and finally, generate personalized cold emails. \\n\\n\\n##\",\n",
      "  \"quiz\": [\n",
      "    {\n",
      "      \"question\": \"What is the main purpose of the tool built in the tutorial?**\",\n",
      "      \"options\": [\n",
      "        \"A. To generate marketing content for social media.\",\n",
      "        \"B. To automate the generation of personalized cold emails.\",\n",
      "        \"C. To analyze customer sentiment from online reviews.\",\n",
      "        \"D. To translate job descriptions into multiple languages.\"\n",
      "      ],\n",
      "      \"answer\": \"B. To automate the generation of personalized cold emails.\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"Which open-source language model is used for text generation and information extraction in the tutorial?**\",\n",
      "      \"options\": [\n",
      "        \"A. GPT-3\",\n",
      "        \"B. BERT\",\n",
      "        \"C. Llama 3.1\",\n",
      "        \"D. BARD\"\n",
      "      ],\n",
      "      \"answer\": \"C. Llama 3.1\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"What type of database is Chroma DB used for in the project?**\",\n",
      "      \"options\": [\n",
      "        \"A. Relational Database\",\n",
      "        \"B. Graph Database\",\n",
      "        \"C. Vector Database\",\n",
      "        \"D. Document Database\"\n",
      "      ],\n",
      "      \"answer\": \"C. Vector Database\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"What is the function of the “portfolio” links included in the generated cold emails?**\",\n",
      "      \"options\": [\n",
      "        \"A. To direct potential clients to case studies and past projects.\",\n",
      "        \"B. To showcase the company's social media presence.\",\n",
      "        \"C. To provide pricing information for different services.\",\n",
      "        \"D. To offer free trials of the company's software.\"\n",
      "      ],\n",
      "      \"answer\": \"A. To direct potential clients to case studies and past projects.\"\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"What framework is used to build the simple user interface for the cold email generator?**\",\n",
      "      \"options\": [\n",
      "        \"A. Flask\",\n",
      "        \"B. Django\",\n",
      "        \"C. React\",\n",
      "        \"D. Streamlit\"\n",
      "      ],\n",
      "      \"answer\": \"D. Streamlit\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import TextFormatter\n",
    "\n",
    "# Configure the API key for Google Generative AI\n",
    "GOOGLE_API_KEY = \"AIzaSyAC1OLrVT3QooZay0B8x3hPoBYLqcT3oNE\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Function to get the transcript of the YouTube video\n",
    "def get_transcript(youtube_url):\n",
    "    try:\n",
    "        video_id = youtube_url.split('v=')[-1]  # Extract video ID from URL\n",
    "        transcript = None\n",
    "        formatter = TextFormatter()\n",
    "\n",
    "        # Try to get the Hindi transcript first\n",
    "        try:\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['hi'])\n",
    "            language = 'hi'\n",
    "        except:\n",
    "            # If Hindi is not available, fall back to English\n",
    "            try:\n",
    "                transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
    "                language = 'en'\n",
    "            except:\n",
    "                print(json.dumps({\"error\": \"Neither Hindi nor English transcript is available.\"}))\n",
    "                return None, None\n",
    "\n",
    "        return formatter.format_transcript(transcript), language\n",
    "    except Exception as e:\n",
    "        print(json.dumps({\"error\": f\"Error fetching transcript: {str(e)}\"}))\n",
    "        return None, None\n",
    "\n",
    "# Function to generate summary and quiz based on the transcript\n",
    "def generate_summary_and_quiz(transcript, num_questions, language):\n",
    "    prompt = f\"\"\"Summarize the following transcript in about 200 words.\n",
    "    Then create a quiz with {num_questions} multiple-choice questions based on the content.\n",
    "    The quiz questions and options should always be in English, regardless of the transcript language.\n",
    "    Format the output as follows:\n",
    "    Summary: [Your summary here]\n",
    "    Quiz:\n",
    "    Q1. [Question in English]\n",
    "    A. [Option A in English]\n",
    "    B. [Option B in English]\n",
    "    C. [Option C in English]\n",
    "    D. [Option D in English]\n",
    "    Correct Answer: [Correct option letter]\n",
    "\n",
    "    [Repeat for all questions]\n",
    "\n",
    "    Transcript: {transcript}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use Google's Generative AI model to generate content\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Function to parse the generated content into summary and quiz format\n",
    "def parse_content(content):\n",
    "    summary = \"\"\n",
    "    quiz = []\n",
    "    \n",
    "    # Extract summary\n",
    "    summary_match = re.search(r\"Summary:(.*?)Quiz:\", content, re.DOTALL | re.IGNORECASE)\n",
    "    if summary_match:\n",
    "        summary = summary_match.group(1).strip()\n",
    "    \n",
    "    # Extract quiz questions\n",
    "    questions = re.findall(r\"Q\\d+\\.(.*?)Correct Answer:\", content, re.DOTALL | re.IGNORECASE)\n",
    "    answers = re.findall(r\"Correct Answer:\\s*(\\w)\", content, re.IGNORECASE)\n",
    "    \n",
    "    for q, a in zip(questions, answers):\n",
    "        question_parts = q.strip().split('\\n')\n",
    "        question_text = question_parts[0].strip()\n",
    "        options = [opt.strip() for opt in question_parts[1:5]]\n",
    "        \n",
    "        quiz.append({\n",
    "            \"question\": question_text,\n",
    "            \"options\": options,\n",
    "            \"answer\": options[ord(a.upper()) - ord('A')]\n",
    "        })\n",
    "    \n",
    "    return summary, quiz\n",
    "\n",
    "# Function to generate the final JSON output\n",
    "def generate_json(youtube_link, num_questions):\n",
    "    transcript, language = get_transcript(youtube_link)\n",
    "    if not transcript:\n",
    "        return None\n",
    "\n",
    "    content = generate_summary_and_quiz(transcript, num_questions, language)\n",
    "    summary, quiz = parse_content(content)\n",
    "\n",
    "    result = {\n",
    "        \"summary\": summary,\n",
    "        \"quiz\": quiz\n",
    "    }\n",
    "\n",
    "    return json.dumps(result, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Main function to handle user input\n",
    "def main():\n",
    "    youtube_link = input(\"Enter the YouTube video link: \")\n",
    "    \n",
    "    # Ask user for the number of quiz questions and validate it\n",
    "    while True:\n",
    "        try:\n",
    "            num_questions = int(input(\"Enter the number of quiz questions: \"))\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer for the number of questions.\")\n",
    "\n",
    "    # Generate JSON content\n",
    "    json_output = generate_json(youtube_link, num_questions)\n",
    "\n",
    "    if json_output:\n",
    "        print(\"Generated Output:\\n\", json_output)\n",
    "    else:\n",
    "        print(json.dumps({\"error\": \"Failed to generate content\"}))\n",
    "\n",
    "# Execute the main function when the script is run\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c548df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
